# Statistical Analysis of Knowledge Graphs

## Introduction to statistical network analysis

Knowledge graphs, as structured representations of information, can be analyzed from multiple perspectives. While the previous chapter focused on algorithmic approaches to traverse and manipulate graphs, this chapter introduces statistical methods for understanding and characterizing knowledge graph properties. Statistical approaches provide quantitative insights into the structure and patterns within knowledge graphs, enabling systematic analysis of complex networks.

Statistical analysis of knowledge graphs serves several important purposes:

1. Characterizing global and local network properties
2. Identifying statistically significant patterns and anomalies
3. Building probabilistic models to describe graph formation and evolution
4. Making predictions about missing or future connections
5. Understanding the underlying processes that generate the observed network structure

Before diving into specific techniques, it's worth noting the distinction between descriptive statistics (which summarize observed properties) and inferential statistics (which draw conclusions about the underlying processes) in the context of knowledge graphs.

::: {#def-network-statistics}

## Network statistics

**Network statistics** are quantitative measures that summarize structural properties of a graph, either globally (characterizing the entire network) or locally (characterizing individual nodes or subgraphs).

:::

## Degree distributions and power laws

One of the most fundamental properties of a network is how connections are distributed among nodes. The degree distribution provides insights into the connectivity patterns of a knowledge graph.

::: {#def-degree-distribution}

## Degree distribution

The **degree distribution** $P(k)$ of a graph is the probability that a randomly selected node has exactly $k$ connections. In directed graphs, we distinguish between the in-degree distribution $P_{in}(k)$ and the out-degree distribution $P_{out}(k)$.

:::

In many real-world networks, including knowledge graphs, the degree distribution often follows a power law.

::: {#def-power-law}

## Power law

A **power law distribution** has the form $P(k) \propto k^{-\gamma}$, where $\gamma$ is a constant parameter typically in the range $2 < \gamma < 3$ for real-world networks. When plotted on a log-log scale, a power law appears as a straight line.

:::

::: {#exm-power-law-knowledge-graph}

## Power law in a knowledge graph

Consider a knowledge graph of scientific publications where nodes represent papers and edges represent citations. Analysis of this network might reveal that the number of papers with $k$ citations follows a power law distribution with $\gamma \approx 2.5$. This means that while most papers receive few citations, a small number of highly influential papers receive a disproportionately large number of citations.

If we plot the frequency of papers against the number of citations on a log-log scale, we would observe an approximately linear relationship:

$$\log(P(k)) \approx -2.5 \log(k) + c$$

where $c$ is a constant.

:::

### Testing for power law distributions

To determine whether a degree distribution follows a power law, several statistical tests can be applied:

1. **Log-log plot visualization**: A straight line on a log-log plot suggests a power law, but is not definitive.
2. **Maximum likelihood estimation** of the power law exponent $\gamma$: $$\gamma \approx 1 + n\left[\sum_{i=1}^{n} \ln \frac{k_i}{k_{min}}\right]^{-1}$$ where $k_i$ are the observed degrees and $k_{min}$ is the minimum degree for which the power law holds.
3. **Kolmogorov-Smirnov test** to compare the observed distribution with a fitted power law.

::: {#exm-power-law-test}

## Testing for power law in citation networks

For a citation network with 10,000 papers, we observe the following:

- The log-log plot shows a nearly linear relationship for papers with more than 5 citations
- Maximum likelihood estimation gives $\gamma = 2.7$
- The Kolmogorov-Smirnov test yields a p-value of 0.08, suggesting that a power law is a plausible fit

Based on these results, we can conclude that the citation pattern in this knowledge graph likely follows a power law distribution for papers with more than 5 citations.

:::

### Implications of power law distributions

The presence of a power law degree distribution has significant implications for knowledge graph analysis:

1. **Scale-free property**: Networks with power law distributions are often called "scale-free" because their structure looks similar at different scales.
2. **Robustness to random failures**: Scale-free networks are resilient against random node removals but vulnerable to targeted attacks on high-degree nodes.
3. **Information diffusion**: Information spreads rapidly in scale-free networks due to the presence of highly connected hubs.
4. **Preferential attachment**: Power laws often emerge from "rich-get-richer" processes where new nodes preferentially connect to already well-connected nodes.

For knowledge graphs, these properties can inform strategies for network maintenance, information retrieval, and resilience planning.

## Clustering coefficients and transitivity

While degree distributions describe the number of connections, clustering coefficients measure how nodes tend to cluster together, forming tightly-knit groups.

::: {#def-clustering-coefficient}

## Clustering coefficient

The **local clustering coefficient** $C_i$ for a node $i$ is the proportion of actual connections among its neighbors relative to the potential connections:

$$C_i = \frac{2|\{e_{jk}: v_j, v_k \in N_i, e_{jk} \in E\}|}{k_i(k_i-1)}$$

where $N_i$ is the neighborhood of node $i$, $k_i$ is the degree of node $i$, and $E$ is the set of edges.

The **global clustering coefficient** (or **transitivity**) is the ratio of closed triplets to the total number of triplets (both open and closed) in the network:

$$C = \frac{3 \times \text{number of triangles}}{\text{number of connected triplets of vertices}}$$

:::

In knowledge graphs, high clustering coefficients often indicate the presence of specialized domains or communities of closely related entities.

::: {#exm-clustering-knowledge-graph}

## Clustering in a social knowledge graph

Consider a knowledge graph representing social relationships where nodes are individuals and edges represent "knows" relationships. A high clustering coefficient would indicate that people tend to form close-knit social groups—if person A knows persons B and C, then B and C are also likely to know each other.

For instance, in an academic collaboration network, we might find:

- The local clustering coefficient for a professor node is 0.75, indicating that 75% of possible connections exist among their collaborators.
- The global clustering coefficient is 0.45, suggesting a moderate overall tendency for researchers to collaborate in groups.

:::

### Relationship between clustering and degree

In many real-world networks, the local clustering coefficient depends on the node degree, often following a relationship:

$$C(k) \sim k^{-\beta}$$

where $\beta$ is typically around 1 for many social and information networks. This relationship indicates that high-degree nodes (hubs) tend to have lower clustering coefficients than low-degree nodes.

### Transitivity and knowledge representation

In knowledge graphs, transitivity has particular relevance for certain relationship types:

1. **Transitive relationships**: Some semantic relationships, like "is-a" or "part-of," are inherently transitive (if A is-a B and B is-a C, then A is-a C).
2. **Non-transitive relationships**: Other relationships, like "interacts-with" or "cites," are not necessarily transitive.

Understanding the transitivity properties of different relationship types can inform knowledge graph completion and inference tasks.

## Centrality measures

Centrality measures identify the most important or influential nodes in a knowledge graph based on their position in the network structure.

::: {#def-degree-centrality}

## Degree centrality

**Degree centrality** is the simplest centrality measure, defined as the number of connections a node has, normalized by the maximum possible connections:

$$C_D(v) = \frac{deg(v)}{n-1}$$

where $deg(v)$ is the degree of node $v$ and $n$ is the total number of nodes in the network.

:::

While degree centrality is easy to compute, it only accounts for direct connections and not a node's position in the overall network structure.

::: {#def-betweenness-centrality}

## Betweenness centrality

**Betweenness centrality** measures the extent to which a node lies on paths between other nodes. It is defined as:

$$C_B(v) = \sum_{s \neq v \neq t} \frac{\sigma_{st}(v)}{\sigma_{st}}$$

where $\sigma_{st}$ is the total number of shortest paths from node $s$ to node $t$, and $\sigma_{st}(v)$ is the number of those paths that pass through node $v$.

:::

Nodes with high betweenness centrality often serve as bridges between different communities or domains in a knowledge graph.

::: {#def-closeness-centrality}

## Closeness centrality

**Closeness centrality** measures how close a node is to all other nodes in the network. It is defined as the reciprocal of the sum of the shortest path distances from a node to all other nodes:

$$C_C(v) = \frac{n-1}{\sum_{u \neq v} d(v, u)}$$

where $d(v, u)$ is the shortest path distance between nodes $v$ and $u$.

:::

Nodes with high closeness centrality can efficiently disseminate information to the rest of the network.

::: {#def-eigenvector-centrality}

## Eigenvector centrality

**Eigenvector centrality** assigns importance to nodes based on the importance of their neighbors. It is defined as the principal eigenvector of the adjacency matrix $A$ of the graph:

$$Ax = \lambda x$$

where $\lambda$ is the largest eigenvalue of $A$ and $x$ is the corresponding eigenvector. The eigenvector centrality of node $i$ is given by the $i$-th element of $x$.

:::

Eigenvector centrality captures the intuition that connections to important nodes contribute more to a node's importance than connections to less important nodes.

::: {#exm-centrality-knowledge-graph}

## Centrality in a biomedical knowledge graph

In a biomedical knowledge graph with entities such as diseases, symptoms, genes, and drugs:

- A disease node with high **degree centrality** might be a complex disorder with many associated symptoms, genes, and treatments.
- A gene node with high **betweenness centrality** might be a key regulator involved in multiple biological pathways, connecting otherwise disparate areas of biology.
- A drug node with high **closeness centrality** might be a broad-spectrum agent that can quickly impact many different biological systems.
- A disease node with high **eigenvector centrality** might be a central disorder connected to many other high-impact diseases, genes, and biological processes.

These centrality measures provide complementary views of importance in the knowledge graph, useful for identifying key entities for further research.

:::

### Practical considerations for centrality computation

Computing centrality measures for large knowledge graphs presents several challenges:

1. **Computational complexity**:

   - Degree centrality: $O(|V|)$
   - Closeness centrality: $O(|V||E|)$
   - Betweenness centrality: $O(|V||E|)$ with approximation algorithms, $O(|V|^3)$ for exact computation
   - Eigenvector centrality: $O(|E|k)$ where $k$ is the number of iterations until convergence

2. **Approximation algorithms** are often necessary for large graphs, particularly for betweenness centrality.

3. **Domain-specific interpretations** of centrality may require customized measures that account for semantic information in knowledge graphs.

## Structural balance and social network analysis

Structural balance theory, originating from social psychology, provides insights into the stability of relationship patterns, particularly in signed networks where relationships can be positive or negative.

::: {#def-structural-balance}

## Structural balance

A signed graph is **structurally balanced** if it can be partitioned into two subsets such that all edges within each subset are positive, and all edges between the subsets are negative. Equivalently, a graph is structurally balanced if all cycles have an even number of negative edges.

:::

The concept can be extended to knowledge graphs that incorporate sentiment or opposition relationships.

::: {#exm-structural-balance-knowledge-graph}

## Structural balance in a political knowledge graph

Consider a knowledge graph representing political entities (politicians, parties, organizations) with signed relationships indicating support (+) or opposition (-). Structural balance would predict that "the enemy of my enemy is my friend" – if politician A opposes politician B, and politician B opposes policy C, then politician A is likely to support policy C.

Analysis of such a knowledge graph might reveal that it's nearly structurally balanced, with only a small number of "unstable" triads, suggesting predictable political alignments.

:::

### Measuring structural balance

To quantify the degree of structural balance in a signed network, we can use:

1. **Balance ratio**: The ratio of balanced triads to the total number of triads in the network.
2. **Frustration index**: The minimum number of edges whose removal (or sign change) would make the network structurally balanced.

These measures help identify how close a knowledge graph is to perfect structural balance and which relationships contribute most to imbalance.

## Random graph models

Random graph models provide a foundation for statistical inference on knowledge graphs by establishing null models against which observed network properties can be compared.

::: {#def-random-graph-model}

## Random graph model

A **random graph model** is a probability distribution over graphs, typically parameterized to match certain properties of observed networks.

:::

### Erdős–Rényi model

The simplest random graph model is the Erdős–Rényi model, which assigns equal probability to all graphs with a fixed number of nodes and edges.

::: {#def-erdos-renyi-model}

## Erdős–Rényi model

The **Erdős–Rényi model** generates random graphs where each possible edge between $n$ nodes exists with a fixed probability $p$, independent of other edges. The model is denoted as $G(n, p)$.

:::

Properties of Erdős–Rényi graphs include:

1. The degree distribution follows a binomial distribution, approaching Poisson for large graphs and small $p$.
2. The average clustering coefficient is $p$, which is often much smaller than in real-world networks.
3. The average path length is approximately $\log(n)/\log(np)$.

::: {#exm-erdos-renyi-comparison}

## Comparing a knowledge graph to an Erdős–Rényi model

For a knowledge graph with 10,000 nodes and 50,000 edges, we can compare its properties with an Erdős–Rényi random graph $G(10000, 0.001)$ where $p = 50000/\binom{10000}{2} \approx 0.001$:

| Property | Knowledge Graph | Erdős–Rényi Model |
| --- | --- | --- |
| Clustering coefficient | 0.15 | 0.001 |
| Average path length | 5.2 | 8.4 |
| Degree distribution | Power law ($\gamma = 2.4$) | Poisson ($\lambda = 10$) |

The significant differences indicate that the knowledge graph has structural properties that cannot be explained by random connections alone.

:::

### Barabási–Albert model

To better model the power law degree distributions observed in many real networks, the Barabási–Albert model incorporates preferential attachment.

::: {#def-barabasi-albert-model}

## Barabási–Albert model

The **Barabási–Albert model** generates random scale-free networks using preferential attachment. Starting with a small connected graph, new nodes are added sequentially, each connecting to $m$ existing nodes with probability proportional to their degree.

:::

Properties of Barabási–Albert graphs include:

1. The degree distribution follows a power law with exponent $\gamma = 3$.
2. The average clustering coefficient is higher than in Erdős–Rényi graphs but still lower than in many real networks.
3. The average path length grows logarithmically with network size, similar to Erdős–Rényi graphs.

::: {#exm-barabasi-albert-knowledge-graph}

## Modeling citation patterns with Barabási–Albert

In a citation knowledge graph, the Barabási–Albert model captures the "rich get richer" phenomenon where highly cited papers are more likely to receive additional citations. By fitting the model parameter $m$ (the number of connections each new node makes), we can simulate the growth of the citation network and predict future citation patterns.

For a citation network with 50,000 papers and a power law exponent of $\gamma = 2.8$, we might find that a Barabási–Albert model with $m = 4$ provides a reasonable approximation of the degree distribution, though other properties like clustering might still differ.

:::

### Stochastic block models

To model community structure in networks, stochastic block models extend random graph models by incorporating group membership.

::: {#def-stochastic-block-model}

## Stochastic block model

A **stochastic block model** partitions nodes into $k$ groups and defines a $k \times k$ matrix $P$ where $P_{rs}$ is the probability of an edge between a node in group $r$ and a node in group $s$.

:::

::: {#exm-stochastic-block-model-knowledge-graph}

## Community structure in a knowledge graph

Consider a knowledge graph of musical entities (artists, albums, songs, genres) that appears to have distinct communities. A stochastic block model might identify 5 communities corresponding to major music genres, with higher connection probabilities within genres than between them.

By fitting a stochastic block model, we can:

1. Identify the optimal number of communities
2. Assign entities to their most likely community
3. Characterize the connection patterns between different communities
4. Predict missing links based on community membership

:::

## Statistical inference on graphs

Statistical inference methods allow us to draw conclusions about the underlying processes that generate knowledge graphs and to make predictions about unobserved properties.

::: {#def-statistical-inference}

## Statistical inference on graphs

**Statistical inference on graphs** involves estimating parameters of probabilistic models from observed graph data and using these models to test hypotheses or make predictions about graph properties.

:::

### Parameter estimation

Fitting random graph models to observed knowledge graphs involves estimating model parameters that maximize the likelihood of observing the given network structure.

::: {#exm-parameter-estimation}

## Estimating parameters of a stochastic block model

For a knowledge graph with apparent community structure, we can estimate:

1. The optimal number of communities $k$ using methods like the Bayesian Information Criterion (BIC)
2. The community assignments of each node using maximum likelihood or Bayesian inference
3. The inter-community connection probabilities $P_{rs}$

These estimated parameters provide insights into the community structure and connection patterns in the knowledge graph.

:::

### Hypothesis testing

Statistical tests can determine whether observed network properties deviate significantly from what would be expected under null models.

::: {#exm-hypothesis-testing}

## Testing for assortative mixing in a knowledge graph

**Assortative mixing** (or homophily) refers to the tendency of nodes to connect with similar nodes. To test whether a knowledge graph exhibits assortative mixing by node degree:

1. Calculate the Pearson correlation coefficient $r$ between the degrees of connected nodes
2. Generate many random networks with the same degree sequence using configuration models
3. Calculate the p-value as the proportion of random networks with correlation coefficients at least as extreme as the observed value

If p < 0.05, we can reject the null hypothesis and conclude that the knowledge graph exhibits significant degree assortativity or disassortativity.

:::

### Link prediction

Statistical models can predict missing or future links in knowledge graphs based on observed network structure.

::: {#def-link-prediction}

## Link prediction

**Link prediction** is the task of predicting the likelihood of a future or missing connection between two nodes in a network based on the observed network structure and possibly node attributes.

:::

Common approaches to link prediction include:

1. **Similarity-based methods** that calculate scores based on the neighborhood of two nodes:

   - Common neighbors: $|N(u) \cap N(v)|$
   - Jaccard coefficient: $\frac{|N(u) \cap N(v)|}{|N(u) \cup N(v)|}$
   - Adamic-Adar index: $\sum_{w \in N(u) \cap N(v)} \frac{1}{\log(|N(w)|)}$

2. **Path-based methods** that consider paths between nodes:

   - Katz index: $\sum_{l=1}^{\infty} \beta^l |paths^{(l)}_{u,v}|$
   - Random walk methods

3. **Probabilistic models** that explicitly model the link formation process:
   - Stochastic block models
   - Latent space models
   - Exponential random graph models (ERGMs)

::: {#exm-link-prediction-knowledge-graph}

## Link prediction in a drug-target knowledge graph

In a biomedical knowledge graph connecting drugs to their target proteins, link prediction can identify potential new drug-target interactions for experimental validation.

Evaluation of different link prediction methods on a subset of known interactions held out for testing might yield:

| Method                 | AUC  | Precision@10 |
| ---------------------- | ---- | ------------ |
| Common neighbors       | 0.72 | 0.45         |
| Jaccard coefficient    | 0.75 | 0.50         |
| Adamic-Adar index      | 0.78 | 0.55         |
| Katz index             | 0.81 | 0.60         |
| Stochastic block model | 0.84 | 0.65         |

The results suggest that considering both local neighborhood structure and global community patterns provides the best predictive performance for this particular knowledge graph.

:::

## Network motifs and graphlets

Network motifs are recurring, statistically significant subgraph patterns that may represent fundamental building blocks of complex networks.

::: {#def-network-motif}

## Network motif

A **network motif** is a subgraph pattern that occurs significantly more frequently in a real network than would be expected in randomized networks with the same degree distribution.

:::

::: {#def-graphlet}

## Graphlet

A **graphlet** is a small, connected, non-isomorphic induced subgraph of a larger network. Unlike motifs, graphlets are not necessarily overrepresented in the network.

:::

### Motif detection and significance

Detecting network motifs involves:

1. Enumerating all subgraphs of a specific size (typically 3-5 nodes) in the network
2. Classifying these subgraphs into isomorphism classes
3. Generating random networks with the same degree sequence
4. Comparing the frequency of each subgraph in the real network to its frequency in the random networks

The statistical significance of a motif is typically measured using the Z-score:

$$Z_i = \frac{N_i^{real} - \bar{N}_i^{rand}}{\sigma_i^{rand}}$$

where $N_i^{real}$ is the frequency of subgraph $i$ in the real network, and $\bar{N}_i^{rand}$ and $\sigma_i^{rand}$ are the mean and standard deviation of its frequency in randomized networks.

::: {#exm-motifs-knowledge-graph}

## Motifs in a gene regulatory knowledge graph

In a gene regulatory network, where nodes represent genes and directed edges represent regulatory interactions, motif analysis might reveal:

1. Feed-forward loops (A → B, B → C, A → C) are significantly overrepresented (Z-score = 12.5)
2. Feedback loops (A → B, B → C, C → A) are underrepresented (Z-score = -3.2)
3. Bi-fan motifs (A → C, A → D, B → C, B → D) occur at expected frequencies (Z-score = 0.8)

These motif patterns suggest that the gene regulatory network favors unidirectional information flow and avoids circular regulation, which aligns with the need for stable and responsive regulatory systems.

:::

### Graphlet-based network comparison

Graphlets provide a way to compare network structures and characterize the local network environment of nodes.

::: {#def-graphlet-degree-vector}

## Graphlet degree vector

The **graphlet degree vector (GDV)** of a node is a vector whose elements count the number of times the node appears in each position (orbit) of all possible graphlets up to a certain size.

:::

The similarity between nodes or networks can be measured using the correlation between their graphlet degree vectors, providing a more comprehensive comparison than simple degree-based measures.

::: {#exm-graphlet-comparison}

## Comparing protein interaction networks using graphlets

To compare protein interaction networks from different species, we can:

1. Compute the graphlet frequency distribution for each network (the frequency of each graphlet type)
2. Calculate the relative graphlet frequency distance (RGF-distance) between networks
3. Identify evolutionarily conserved network patterns across species

This analysis might reveal that certain graphlet patterns are evolutionarily conserved, suggesting fundamental organizational principles in protein interaction networks across species.

:::

## Multilayer and heterogeneous network analysis

Knowledge graphs often contain multiple types of nodes and relationships, requiring specialized analytical approaches.

::: {#def-multilayer-network}

## Multilayer network

A **multilayer network** is a network with multiple layers, where each layer represents a different type of relationship between the same set of nodes. Formally, it can be represented as $M = (V, E, L)$ where $V$ is the set of nodes, $L$ is the set of layers, and $E \subseteq V \times V \times L$ is the set of edges.

:::

::: {#def-heterogeneous-network}

## Heterogeneous network

A **heterogeneous network** (or heterogeneous information network) is a network with multiple types of nodes and/or multiple types of edges. Formally, it can be represented as $G = (V, E, \phi, \psi)$ where $\phi: V \rightarrow T_V$ maps nodes to node types and $\psi: E \rightarrow T_E$ maps edges to edge types.

:::

Knowledge graphs are typically heterogeneous networks, with entities of various types connected by different semantic relationships.

### Metrics for multilayer networks

Several metrics have been extended to multilayer and heterogeneous networks:

1. **Multilayer clustering coefficient**: $$C_i^{multi} = \frac{2\sum_{j,h} \sum_{\alpha, \beta} a_{ij}^{\alpha} a_{ih}^{\beta} a_{jh}^{\gamma}}{k_i(k_i-1)}$$ where $a_{ij}^{\alpha}$ indicates the presence of an edge between nodes $i$ and $j$ in layer $\alpha$.

2. **Heterogeneous centrality measures** that account for different node and edge types, often incorporating semantic information.

::: {#exm-multilayer-knowledge-graph}

## Multilayer analysis of an academic knowledge graph

An academic knowledge graph might contain multiple relationship types between researchers:

- Co-authorship relationships
- Citation relationships
- Institutional affiliations
- Research topic similarities

Multilayer analysis could reveal:

- Researchers who are central in one layer (e.g., highly cited) but peripheral in another (e.g., few collaborations)
- Communities that are strongly connected across multiple layers, indicating robust research groups
- Patterns of influence that spread across different types of academic relationships

:::

### Metapath analysis

In heterogeneous networks, paths that follow a specific sequence of node and edge types (metapaths) provide semantic context for relationships.

::: {#def-metapath}

## Metapath

A **metapath** is a path defined on a network schema $S = (A, R)$ and is denoted by a sequence of node types and edge types: $A_1 \xrightarrow{R_1} A_2 \xrightarrow{R_2} ... \xrightarrow{R_{l-1}} A_l$.

:::

Metapath-based similarity measures can capture complex semantic relationships in knowledge graphs.

::: {#exm-metapath-knowledge-graph}

## Metapaths in a movie knowledge graph

In a movie knowledge graph with entity types {Movie, Actor, Director, Genre}, different metapaths capture different semantic relationships:

1. Movie → Actor → Movie: Movies connected by common actors
2. Movie → Director → Movie: Movies by the same director
3. Movie → Genre → Movie: Movies in the same genre
4. Movie → Actor → Director → Movie: More complex relationships

By analyzing the frequency and importance of different metapaths, we can understand which types of relationships most strongly influence the structure of the knowledge graph.

:::

## Temporal network analysis

Many knowledge graphs include temporal information, requiring methods that can analyze how network structure evolves over time.

::: {#def-temporal-network}

## Temporal network

A **temporal network** (or time-varying network) is a network whose structure changes over time. It can be represented as a sequence of static networks $G(t) = (V(t), E(t))$ for discrete time points $t$, or as a graph with time-stamped edges $G = (V, E, T)$ where $T: E \rightarrow \mathbb{R}$ assigns timestamps to edges.

:::

### Metrics for temporal networks

Several metrics capture the dynamic properties of temporal networks:

1. **Temporal path length**: The minimum time required to travel from one node to another, respecting the temporal ordering of edges.
2. **Temporal betweenness centrality**: The number of shortest temporal paths passing through a node.
3. **Temporal motifs**: Small, recurring, statistically significant temporal subgraph patterns.

::: {#exm-temporal-knowledge-graph}

## Temporal analysis of a news knowledge graph

A news knowledge graph might connect entities (people, organizations, locations) mentioned in news articles, with edges time-stamped by article publication dates.

Temporal analysis might reveal:

- How the prominence of entities (measured by centrality) changes over time in response to events
- The evolution of community structures as new topics emerge and old ones fade
- Temporal motifs corresponding to recurring news patterns (e.g., announcement → reaction → analysis)
- Early indicators of emerging trends or issues based on temporal network patterns

:::

### Change point detection

Change point detection identifies significant structural changes in temporal networks.

::: {#def-change-point-detection}

## Change point detection

**Change point detection** in temporal networks aims to identify time points $t$ where the network structure $G(t)$ undergoes significant changes relative to $G(t-1)$.

:::

Methods for change point detection include:

1. Monitoring global network statistics (density, clustering, diameter) over time
2. Detecting significant changes in community structure
3. Using statistical tests to identify when the network generating process changes

::: {#exm-change-point-knowledge-graph}

## Change points in a financial knowledge graph

In a financial knowledge graph connecting companies through various relationships (ownership, supply chain, joint ventures), change point detection might identify:

- Major market disruptions reflected in rapid structural changes
- Industry reorganizations following regulatory changes
- Merger and acquisition waves that reshape industry structure
- Financial crises that alter the pattern of financial relationships

:::

## Applications of statistical network analysis

Statistical analysis of knowledge graphs enables numerous applications across different domains.

### Anomaly detection

Statistical methods can identify entities or relationships that deviate significantly from expected patterns.

::: {#exm-anomaly-detection}

## Fraud detection in a financial knowledge graph

In a financial transaction knowledge graph, statistical anomaly detection might flag:

- Accounts with unusual connection patterns based on degree distribution analysis
- Transaction cycles that violate structural balance principles
- Temporal motifs associated with known fraud schemes
- Entities with centrality measures that change abruptly over time

:::

### Domain-specific insights

Statistical analysis can reveal domain-specific patterns and characteristics in specialized knowledge graphs.

::: {#exm-domain-insights}

## Statistical insights from a healthcare knowledge graph

Analysis of a healthcare knowledge graph connecting patients, diagnoses, procedures, and medications might reveal:

- Comorbidity patterns through community detection
- Critical medical entities through centrality analysis
- Typical treatment pathways through temporal motif analysis
- Unusual patient trajectories through anomaly detection

:::

### Comparative network analysis

Statistical methods enable systematic comparison of knowledge graphs across different domains, time periods, or sources.

::: {#exm-comparative-analysis}

## Comparing scientific knowledge graphs over time

Statistical comparison of biomedical knowledge graphs from different decades might reveal:

- Changes in the power law exponent of citation distributions
- Evolution of research communities detected through stochastic block models
- Increasing or decreasing clustering coefficients reflecting specialization patterns
- Changes in characteristic path lengths as fields become more integrated or fragmented

:::

## Limitations and challenges

Statistical analysis of knowledge graphs faces several challenges:

1. **Scale**: Large knowledge graphs may contain billions of entities and relationships, requiring efficient algorithms and sampling approaches.
2. **Heterogeneity**: Multiple node and edge types complicate the application of traditional network statistics.
3. **Incompleteness**: Missing data can significantly bias statistical measures and inferences.
4. **Temporal dynamics**: Capturing the evolving nature of knowledge graphs requires specialized temporal statistics.
5. **Semantic context**: Pure topological analysis may miss important semantic aspects of knowledge graphs.

Addressing these challenges requires combining statistical approaches with domain knowledge and semantic understanding.

## Machine learning approaches to statistical analysis

Machine learning techniques increasingly complement traditional statistical methods for knowledge graph analysis.

::: {#exm-ml-statistical-analysis}

## Combining statistics and machine learning

Deep learning models can be used to:

- Learn latent representations (embeddings) that capture both structural and semantic aspects of knowledge graphs
- Predict network statistics for large graphs where direct computation is infeasible
- Detect complex patterns that might not be captured by predefined statistical measures
- Integrate heterogeneous information types in a unified framework

For example, a graph neural network trained on a subset of a large biomedical knowledge graph could predict centrality measures for the entire graph, or identify communities that align with clinical disease classifications.

:::

### Graph embeddings for statistical analysis

Graph embedding techniques map nodes, edges, or subgraphs to low-dimensional vector spaces, enabling efficient statistical analysis.

::: {#def-graph-embedding}

## Graph embedding

A **graph embedding** is a mapping $f: V \rightarrow \mathbb{R}^d$ that transforms nodes (or other graph elements) into low-dimensional vectors while preserving relevant structural and semantic information.

:::

Embeddings can be used to:

1. Visualize network structure in 2D or 3D spaces
2. Apply traditional statistical methods to vectorized representations
3. Cluster nodes based on structural similarity
4. Predict statistical properties of new or unobserved nodes

::: {#exm-embedding-statistical-analysis}

## Using embeddings for knowledge graph statistics

After embedding a scientific knowledge graph using a method like TransE or node2vec:

- The distribution of embedding vectors might reveal inherent dimensionality of the knowledge domain
- Clusters in the embedding space might correspond to scientific disciplines or research areas
- Distances in the embedding space might correlate with semantic similarity or influence relationships
- Outliers in the embedding space might represent interdisciplinary entities that bridge multiple research areas

:::

## Bayesian approaches to network analysis

Bayesian methods provide a principled framework for incorporating prior knowledge and quantifying uncertainty in network analysis.

::: {#def-bayesian-network-analysis}

## Bayesian network analysis

**Bayesian network analysis** applies Bayesian statistical methods to network data, treating network structures and parameters as random variables with prior and posterior distributions.

:::

Key Bayesian approaches include:

1. **Bayesian community detection**: Inferring community structure with uncertainty quantification
2. **Bayesian exponential random graph models (BERGMs)**: Modeling network formation processes with prior knowledge
3. **Nonparametric Bayesian models**: Allowing the number of communities or other structural features to be learned from data

::: {#exm-bayesian-knowledge-graph}

## Bayesian analysis of a citation knowledge graph

For a citation network of scientific papers:

- A Bayesian stochastic block model might infer the most likely community structure along with the probability of alternative structures
- A Bayesian approach to link prediction would provide not just predicted links but confidence intervals for these predictions
- Nonparametric Bayesian models could determine the optimal number of research communities without pre-specifying this parameter
- Incorporating prior knowledge about established research fields could improve community detection in emerging interdisciplinary areas

:::

### Uncertainty quantification

A key advantage of Bayesian approaches is explicit quantification of uncertainty in network statistics and inferences.

::: {#exm-uncertainty-quantification}

## Uncertainty in centrality measures

Instead of a single centrality value for each node, Bayesian approaches provide a distribution of possible values:

- The mean represents the expected centrality
- The variance captures uncertainty due to network sampling, missing data, or model assumptions
- Credible intervals provide a range of plausible values

This uncertainty quantification is particularly valuable for knowledge graphs with incomplete information or when making high-stakes decisions based on network analysis.

:::

## Information-theoretic approaches

Information theory provides powerful tools for analyzing the complexity and information content of knowledge graphs.

::: {#def-graph-entropy}

## Graph entropy

**Graph entropy** measures the amount of information contained in a graph structure. For a graph with adjacency matrix $A$, one definition of entropy is:

$$H(G) = -\sum_{i,j} p_{ij} \log p_{ij}$$

where $p_{ij}$ is the normalized edge weight between nodes $i$ and $j$.

:::

Information-theoretic measures can quantify:

1. The complexity of knowledge graph structure
2. The information gain from adding new entities or relationships
3. The mutual information between different layers or aspects of the knowledge graph
4. The minimum description length of the graph, which relates to its compressibility

::: {#exm-information-theory-knowledge-graph}

## Information theory in knowledge graph analysis

For a knowledge graph representing product-customer relationships:

- Entropy analysis might reveal which product categories contribute most to the structural complexity of the network
- Mutual information between purchase patterns and demographic layers could quantify which customer attributes best predict purchasing behavior
- Minimum description length principles could identify the optimal community structure that balances model complexity with explanatory power
- Information gain analysis could prioritize which missing relationships would most increase the information content of the knowledge graph if discovered

:::

## Statistical validation and reliability

Ensuring the reliability of statistical analyses is crucial, particularly for knowledge graphs that inform decision-making processes.

::: {#def-statistical-validation}

## Statistical validation

**Statistical validation** in network analysis refers to the process of assessing the reliability, significance, and robustness of network statistics and inferences.

:::

Key validation approaches include:

1. **Bootstrapping**: Resampling edges or nodes to estimate the variability of network statistics
2. **Permutation tests**: Generating null distributions by randomly rewiring the network while preserving certain properties
3. **Cross-validation**: Holding out portions of the network to assess predictive performance
4. **Sensitivity analysis**: Examining how network statistics change when small perturbations are applied to the graph

::: {#exm-validation-knowledge-graph}

## Validating community detection in a social knowledge graph

To validate communities detected in a social knowledge graph:

1. **Bootstrapping**: Generate 1000 resampled networks by randomly removing 10% of edges and rerunning the community detection algorithm
2. **Stability assessment**: Calculate the adjusted Rand index between community assignments in the original and resampled networks
3. **Significance testing**: Compare the modularity of detected communities to a null distribution from configuration model random graphs
4. **External validation**: Correlate community assignments with known attributes (e.g., demographic information, interests) to assess real-world relevance
5. **Robustness check**: Test whether similar communities are detected with different algorithms (e.g., Louvain, InfoMap, spectral clustering)

Results might show that certain communities are highly stable and statistically significant, while others are sensitive to small perturbations in the network, suggesting caution in interpretation.

:::

## Practical considerations for large-scale knowledge graphs

Applying statistical analysis to large-scale knowledge graphs involves several practical considerations:

### Sampling strategies

For massive knowledge graphs, analyzing a representative sample can provide accurate statistical estimates more efficiently.

::: {#exm-sampling-knowledge-graph}

## Sampling strategies for a web-scale knowledge graph

For a web-scale knowledge graph with billions of entities and relationships:

1. **Random node sampling**: Select a random subset of entities and their immediate connections
2. **Random edge sampling**: Select a random subset of relationships
3. **Forest fire sampling**: Start from seed nodes and probabilistically "burn" to neighboring nodes
4. **Metropolis-Hastings Random Walk (MHRW)**: Use a Markov Chain Monte Carlo approach to sample nodes with probability proportional to a target distribution

Evaluation might show that forest fire sampling preserves degree distribution and clustering properties better than random sampling, while MHRW provides the most accurate estimates of global network statistics.

:::

### Distributed and parallel computation

Large-scale statistical analysis often requires distributed computing frameworks.

::: {#exm-distributed-computation}

## Computing centrality measures at scale

For a knowledge graph with hundreds of millions of nodes:

1. **Graph partitioning**: Divide the graph into overlapping subgraphs
2. **Parallel processing**: Compute local statistics for each subgraph
3. **Aggregation**: Combine local statistics to estimate global measures
4. **Approximation algorithms**: Use approximate algorithms with theoretical error bounds

Using a distributed framework like Apache Spark GraphX, approximate betweenness centrality computation that would take weeks on a single machine can be completed in hours on a cluster.

:::

### Incremental and streaming approaches

For continuously evolving knowledge graphs, incremental approaches maintain up-to-date statistics without full recomputation.

::: {#exm-incremental-statistics}

## Incremental clustering coefficient computation

For a dynamic knowledge graph that receives millions of updates daily:

1. **Delta maintenance**: Update only the statistics affected by new or removed edges
2. **Sliding window analysis**: Compute statistics over recent time windows
3. **Sketch-based approximation**: Maintain probabilistic data structures that approximate statistics
4. **Online algorithms**: Update statistics as new data arrives without storing the entire history

An evaluation might show that delta maintenance approaches provide exact results but scale linearly with update frequency, while sketch-based methods offer constant-time updates with a small approximation error.

:::

## Case studies in knowledge graph statistics

### Case study: Scientific collaboration networks

::: {#exm-science-network-case-study}

## Statistical analysis of scientific collaboration

Analysis of a scientific collaboration knowledge graph connecting researchers, institutions, publications, and research topics revealed:

1. **Power law analysis**: The distribution of publications per researcher followed a power law with exponent $\gamma = 2.4$, indicating substantial inequality in scientific productivity.

2. **Small-world properties**: Despite containing over 5 million researchers, the network had an average path length of 5.9 and a clustering coefficient of 0.24, confirming the "small world" nature of scientific collaboration.

3. **Community detection**: Stochastic block modeling identified 87 distinct research communities, broadly aligned with traditional academic disciplines but with significant interdisciplinary bridges.

4. **Temporal evolution**: Time-series analysis of centrality measures identified emerging research areas before they became widely recognized, based on rapid increases in the betweenness centrality of certain topics.

5. **Link prediction**: A supervised machine learning approach incorporating network statistics achieved 78% accuracy in predicting future collaborations, significantly outperforming models based solely on topic similarity or institutional proximity.

:::

### Case study: Biomedical knowledge integration

::: {#exm-biomedical-knowledge-graph}

## Statistical analysis for biomedical discovery

A comprehensive biomedical knowledge graph integrating data from genomics, proteomics, drug databases, and clinical records was analyzed to identify potential drug repurposing candidates:

1. **Metapath analysis**: The metapath "Drug → Protein → Disease" was found to be highly predictive of therapeutic relationships, with a precision of 0.72 at detecting known treatments.

2. **Motif analysis**: Three-node motifs containing both positive and negative regulatory relationships were significantly overrepresented around successful drug targets compared to random expectation (Z-score = 8.3).

3. **Centrality analysis**: Proteins with high betweenness centrality but moderate degree centrality were found to be ideal drug targets, balancing system-wide influence with limited side effects.

4. **Community detection**: Bayesian community detection with domain-specific priors identified functional modules corresponding to biological pathways with 89% alignment to expert-curated pathway databases.

5. **Anomaly detection**: Statistical outliers in the graph structure successfully flagged data integration errors in approximately 0.5% of the knowledge graph, improving overall data quality.

:::

## Integrating domain knowledge with statistical analysis

The most effective analyses of knowledge graphs combine statistical methods with domain-specific knowledge.

::: {#exm-domain-integration}

## Integrating domain knowledge in financial network analysis

For a financial knowledge graph representing corporate relationships:

1. **Semantically weighted edges**: Edge weights incorporate domain knowledge about the strength of different relationship types (ownership > board membership > business partnership)

2. **Domain-informed null models**: Random graph models preserve industry-specific structural features rather than just degree distributions

3. **Hybrid centrality measures**: Custom centrality metrics combine structural importance with domain-specific importance factors like market capitalization or regulatory significance

4. **Constrained community detection**: Community detection algorithms incorporate known constraints like regulatory categories or geographic limitations

5. **Interpretability enhancement**: Statistical results are automatically annotated with domain-specific explanations to facilitate understanding by financial experts

:::

## Further reading

For readers interested in delving deeper into statistical analysis of knowledge graphs and network science, the following resources provide valuable extensions to the concepts covered in this chapter:

1. Barabási, A.-L. (2016). _Network Science_. Cambridge University Press.

   - A comprehensive introduction to network science fundamentals, covering many of the statistical methods discussed in this chapter.

2. Newman, M. (2018). _Networks_ (2nd ed.). Oxford University Press.

   - An excellent reference for mathematical and statistical methods in network analysis, including detailed derivations and algorithms.

3. Getoor, L., & Diehl, C. P. (2005). Link mining: A survey. _ACM SIGKDD Explorations Newsletter, 7_(2), 3-12.

   - Provides an overview of statistical and machine learning methods for analyzing linked data, with relevance to knowledge graphs.

4. Goldenberg, A., Zheng, A. X., Fienberg, S. E., & Airoldi, E. M. (2010). A survey of statistical network models. _Foundations and Trends in Machine Learning, 2_(2), 129-233.

   - A thorough survey of statistical models for networks, including random graph models and latent variable approaches.

5. Dong, X., Gabrilovich, E., Heitz, G., Horn, W., Lao, N., Murphy, K., Strohmann, T., Sun, S., & Zhang, W. (2014). Knowledge vault: A web-scale approach to probabilistic knowledge fusion. _Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining_, 601-610.

   - Describes statistical approaches to knowledge graph construction and evaluation at web scale.

6. Holme, P., & Saramäki, J. (2012). Temporal networks. _Physics Reports, 519_(3), 97-125.

   - Comprehensive review of methods for analyzing dynamic networks, applicable to temporal knowledge graphs.

7. Kolaczyk, E. D., & Csárdi, G. (2014). _Statistical Analysis of Network Data with R_. Springer.

   - Practical guide to implementing network statistics, with code examples and case studies.

8. Leskovec, J., Lang, K. J., Dasgupta, A., & Mahoney, M. W. (2009). Community structure in large networks: Natural cluster sizes and the absence of large well-defined clusters. _Internet Mathematics, 6_(1), 29-123.

   - Detailed study of community structure in large-scale networks with important implications for knowledge graph analysis.

9. Milo, R., Shen-Orr, S., Itzkovitz, S., Kashtan, N., Chklovskii, D., & Alon, U. (2002). Network motifs: Simple building blocks of complex networks. _Science, 298_(5594), 824-827.

   - Foundational paper on network motifs, introducing concepts and analytical approaches.

10. Kivelä, M., Arenas, A., Barthelemy, M., Gleeson, J. P., Moreno, Y., & Porter, M. A. (2014). Multilayer networks. _Journal of Complex Networks, 2_(3), 203-271.
    - Comprehensive review of methods for analyzing multilayer networks, with applications to heterogeneous knowledge graphs.

These resources span from theoretical foundations to practical applications, providing readers with both breadth and depth in the field of statistical network analysis as applied to knowledge graphs.
